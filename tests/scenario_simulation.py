"""
Cogman Tools - Real-world Scenario Simulation
‡∏à‡∏≥‡∏•‡∏≠‡∏á‡∏™‡∏ñ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏à‡∏£‡∏¥‡∏á‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡πÑ‡∏î‡πâ‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô
"""

import numpy as np
import time
import sys
from cogman_tools import EIMASAnalyzer


def print_header(title):
    print(f"\n{'=' * 60}")
    print(f"üé¨ SCENARIO: {title}")
    print(f"{'=' * 60}")


def simulate_scenarios():
    print("üöÄ Starting Cogman Tools - Production Simulation...")

    # Setup Analyzer
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á Baseline ‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏õ‡∏Å‡∏ï‡∏¥ (Random Normal distribution ‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∏‡∏î‡∏°‡∏Ñ‡∏ï‡∏¥‡∏Ç‡∏≠‡∏á High Entropy Embedding)
    baseline_data = [np.random.randn(768) for _ in range(50)]
    analyzer = EIMASAnalyzer(baseline_embeddings=baseline_data, enable_monitoring=True)

    # ---------------------------------------------------------
    # Scenario 1: The "Silent Death" (Model Collapse)
    # ‡∏™‡∏ñ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ì‡πå: ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏û‡∏±‡∏á ‡πÄ‡∏á‡∏µ‡∏¢‡∏ö‡πÜ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏™‡πà‡∏á‡∏Ñ‡πà‡∏≤ Vector ‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô 0 ‡∏´‡∏£‡∏∑‡∏≠‡∏Ñ‡πà‡∏≤‡∏ã‡πâ‡∏≥‡πÜ ‡∏≠‡∏≠‡∏Å‡∏°‡∏≤
    # ---------------------------------------------------------
    print_header("1. Model Collapse (Silent Failure)")
    print("üìù Context: Model ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏£‡∏ß‡∏ô ‡∏™‡πà‡∏á‡∏Ñ‡πà‡∏≤ Zero Vectors ‡∏≠‡∏≠‡∏Å‡∏°‡∏≤‡∏õ‡∏ô‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏£‡∏¥‡∏á")

    mixed_batch = []
    # ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡∏µ 5 ‡∏ï‡∏±‡∏ß
    mixed_batch.extend([np.random.randn(768) for _ in range(5)])
    # ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏û‡∏±‡∏á (Zero/Sparse Vectors) 3 ‡∏ï‡∏±‡∏ß
    sparse_vector = np.zeros(768);
    sparse_vector[:5] = 1.0  # ‡∏°‡∏µ‡∏Ñ‡πà‡∏≤‡πÅ‡∏Ñ‡πà 5 dimension
    mixed_batch.extend([sparse_vector for _ in range(3)])

    print("\n[Monitoring Log]")
    for i, emb in enumerate(mixed_batch):
        # Ingest ‡∏ó‡∏µ‡∏•‡∏∞‡∏ï‡∏±‡∏ß‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô Real-time
        result = analyzer.ingest_embedding(emb, embedding_id=f"stream_s1_{i}")

        # ‡∏î‡∏∂‡∏á‡∏Ñ‡πà‡∏≤ S (Signal Quality) ‡∏°‡∏≤‡πÇ‡∏ä‡∏ß‡πå
        s_score = result['quality_analysis']['signal_quality']
        status = "‚úÖ OK" if s_score > 0.8 else "‚ùå COLLAPSED"

        print(f"  Time {i}: Signal Quality = {s_score:.4f} | {status}")

    alerts = analyzer.get_alerts(level='WARNING')
    print(f"\nüö® Alerts Triggered: {len(alerts)} (Expected: ~3)")
    if len(alerts) > 0:
        print(f"  Latest Alert: {alerts[-1].message}")

    # ---------------------------------------------------------
    # Scenario 2: The "Slow Drift" (Concept Drift)
    # ‡∏™‡∏ñ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ì‡πå: ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡πà‡∏≠‡∏¢‡πÜ ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡∏ï‡∏≤‡πÑ‡∏õ‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏¢‡πÜ (Drift) ‡∏à‡∏ô‡∏´‡∏•‡∏∏‡∏î Baseline
    # ---------------------------------------------------------
    print_header("2. Gradual Concept Drift")
    print("üìù Context: ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• User ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏û‡∏§‡∏ï‡∏¥‡∏Å‡∏£‡∏£‡∏°‡∏ó‡∏µ‡∏•‡∏∞‡∏ô‡∏¥‡∏î (Shift Mean)")

    # Clear monitoring buffer (keep deque type)
    analyzer.monitoring_buffer.clear()

    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏Ñ‡πà‡∏≠‡∏¢‡πÜ "‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô" ‡∏´‡∏ô‡∏µ‡∏à‡∏≤‡∏Å Baseline (Mean=0)
    print("\n[Monitoring Drift]")
    baseline_mean = np.mean(baseline_data, axis=0)

    for t in range(1, 6):
        # Shift ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ó‡∏µ‡∏•‡∏∞ 0.2 (‡∏•‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏£‡∏á‡∏•‡∏á‡∏ô‡∏¥‡∏î‡∏ô‡∏∂‡∏á‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÄ‡∏´‡πá‡∏ô‡∏Å‡∏£‡∏≤‡∏ü‡∏Ñ‡πà‡∏≠‡∏¢‡πÜ ‡∏Ç‡∏∂‡πâ‡∏ô)
        drift_factor = t * 0.2
        
        # FIX: ‡∏™‡∏£‡πâ‡∏≤‡∏á Batch ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• 10 ‡∏ï‡∏±‡∏ß (‡πÅ‡∏ó‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏™‡πà‡∏á‡πÑ‡∏õ‡∏ï‡∏±‡∏ß‡πÄ‡∏î‡∏µ‡∏¢‡∏ß)
        # ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Distribution ‡πÑ‡∏î‡πâ‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏¥‡∏î Divide by Zero
        drifted_batch = [
            np.random.randn(768) + (np.ones(768) * drift_factor)
            for _ in range(10)
        ]

        # ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Å‡∏±‡∏ö Baseline ‡πÄ‡∏î‡∏¥‡∏°
        result = analyzer.comprehensive_analysis(drifted_batch)
        dist_shift = result['core_analysis']['cluster_analysis']['distribution_shift']

        # Check Status
        status = result['core_analysis']['operational_status'].status

        # Visualization
        bar_length = int(dist_shift * 2)  # Scale bar
        bar = "‚ñà" * bar_length
        print(f"  Month {t}: Shift = {dist_shift:.2f} {bar:<15} | Status: {status}")

    # ---------------------------------------------------------
    # Scenario 3: The "Attack" (Anomaly Spike)
    # ‡∏™‡∏ñ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ì‡πå: ‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡∏¢‡∏∞ (Random Noise ‡∏ó‡∏µ‡πà distribution ‡∏ú‡∏¥‡∏î‡πÄ‡∏û‡∏µ‡πâ‡∏¢‡∏ô) ‡∏ñ‡∏•‡πà‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡∏°‡∏≤
    # ---------------------------------------------------------
    print_header("3. Anomaly Spike (Potential Attack)")
    print("üìù Context: ‡πÄ‡∏à‡∏≠‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Outlier ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Ñ‡∏£‡∏µ‡∏¢‡∏î (Stress) ‡∏™‡∏π‡∏á‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥")

    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏°‡∏µ Variance ‡∏™‡∏π‡∏á‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥ (High Energy Noise)
    attack_embeddings = [np.random.randn(768) * 5.0 for _ in range(5)]

    anomaly_result = analyzer.anomaly_detection(attack_embeddings)
    stress_index = anomaly_result['stress_index']

    print(f"\nüìä Batch Analysis Result:")
    print(f"  Anomaly Density: {anomaly_result['anomaly_density']:.1%}")
    print(f"  Stress Index:    {stress_index:.2f} (Normal < 1.0)")

    if stress_index > 2.0:
        print("  ‚ö†Ô∏è  CRITICAL: High Stress Detected! System might be under attack or broken.")
    else:
        print("  ‚úÖ  System Stable")

    print("\n" + "=" * 60)
    print("‚úÖ Simulation Completed. Ready for deployment.")
    print("=" * 60)


if __name__ == "__main__":
    simulate_scenarios()